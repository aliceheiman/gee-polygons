{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3412d5d",
   "metadata": {},
   "source": [
    "# export\n",
    "\n",
    "> Export API for large-scale batch extraction to Google Drive or Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa1d548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96abe814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea8db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from __future__ import annotations\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional, Literal, List, Dict\n",
    "import time\n",
    "\n",
    "import ee"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be871a1b",
   "metadata": {},
   "source": [
    "## ExportDestination\n",
    "\n",
    "Configuration for where to export results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9465194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class ExportDestination:\n",
    "    \"\"\"Configuration for export destination.\n",
    "\n",
    "    Attributes:\n",
    "        type: 'drive' for Google Drive, 'cloud_storage' for GCS\n",
    "        folder: Drive folder name or GCS bucket/prefix\n",
    "        file_prefix: Prefix for output filenames (default 'extraction')\n",
    "        file_format: Output format - 'CSV' or 'GeoJSON' (default 'CSV')\n",
    "    \"\"\"\n",
    "    type: Literal['drive', 'cloud_storage']\n",
    "    folder: str\n",
    "    file_prefix: str = 'extraction'\n",
    "    file_format: Literal['CSV', 'GeoJSON'] = 'CSV'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb9ed8bc",
   "metadata": {},
   "source": [
    "## ExportConfig\n",
    "\n",
    "Configuration for export behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc20ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class ExportConfig:\n",
    "    \"\"\"Configuration for export behavior.\n",
    "\n",
    "    Attributes:\n",
    "        chunk_size: Number of sites per export task (default 50)\n",
    "        max_concurrent: Maximum concurrent tasks (default 10)\n",
    "        description_prefix: Prefix for GEE task descriptions\n",
    "    \"\"\"\n",
    "    chunk_size: int = 50\n",
    "    max_concurrent: int = 10\n",
    "    description_prefix: str = 'gee_polygons_export'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b98f4a6",
   "metadata": {},
   "source": [
    "## ExportTask\n",
    "\n",
    "Handle to running or completed export tasks. Provides methods to monitor progress, wait for completion, and retrieve results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e84e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@dataclass\n",
    "class ExportTask:\n",
    "    \"\"\"Handle to running or completed export tasks.\n",
    "\n",
    "    Provides methods to monitor progress, wait for completion,\n",
    "    and retrieve results information.\n",
    "\n",
    "    Attributes:\n",
    "        task_ids: List of GEE task IDs\n",
    "        destination: Export destination configuration\n",
    "        config: Export configuration used\n",
    "        chunk_mapping: Mapping of task_id to (start_idx, end_idx) tuples\n",
    "    \"\"\"\n",
    "    task_ids: List[str]\n",
    "    destination: ExportDestination\n",
    "    config: ExportConfig\n",
    "    chunk_mapping: Dict[str, tuple] = field(default_factory=dict)\n",
    "\n",
    "    def status(self) -> Dict[str, str]:\n",
    "        \"\"\"Get status of all tasks.\n",
    "\n",
    "        Returns:\n",
    "            Dict mapping task_id to status string:\n",
    "            'READY', 'RUNNING', 'COMPLETED', 'FAILED', 'CANCELLED', 'UNKNOWN'\n",
    "        \"\"\"\n",
    "        statuses = {}\n",
    "        for task_id in self.task_ids:\n",
    "            try:\n",
    "                task_status = ee.data.getTaskStatus(task_id)\n",
    "                if task_status:\n",
    "                    statuses[task_id] = task_status[0].get('state', 'UNKNOWN')\n",
    "                else:\n",
    "                    statuses[task_id] = 'UNKNOWN'\n",
    "            except Exception:\n",
    "                statuses[task_id] = 'UNKNOWN'\n",
    "        return statuses\n",
    "\n",
    "    def summary(self) -> Dict[str, int]:\n",
    "        \"\"\"Get summary counts by status.\n",
    "\n",
    "        Returns:\n",
    "            Dict with counts per status, e.g. {'COMPLETED': 10, 'RUNNING': 5}\n",
    "        \"\"\"\n",
    "        statuses = self.status()\n",
    "        summary = {}\n",
    "        for status in statuses.values():\n",
    "            summary[status] = summary.get(status, 0) + 1\n",
    "        return summary\n",
    "\n",
    "    def wait(\n",
    "        self,\n",
    "        timeout_minutes: int = 60,\n",
    "        poll_interval_sec: int = 30,\n",
    "        progress: bool = True\n",
    "    ) -> bool:\n",
    "        \"\"\"Wait for all tasks to complete.\n",
    "\n",
    "        Args:\n",
    "            timeout_minutes: Maximum wait time (default 60)\n",
    "            poll_interval_sec: Time between status checks (default 30)\n",
    "            progress: Show progress bar if tqdm available\n",
    "\n",
    "        Returns:\n",
    "            True if all tasks completed successfully, False otherwise\n",
    "        \"\"\"\n",
    "        start = time.time()\n",
    "        timeout_sec = timeout_minutes * 60\n",
    "\n",
    "        completed = set()\n",
    "        pbar = None\n",
    "\n",
    "        if progress:\n",
    "            try:\n",
    "                from tqdm.auto import tqdm\n",
    "                pbar = tqdm(total=len(self.task_ids), desc=\"Export tasks\")\n",
    "            except ImportError:\n",
    "                pass\n",
    "\n",
    "        try:\n",
    "            while time.time() - start < timeout_sec:\n",
    "                statuses = self.status()\n",
    "\n",
    "                for tid, status in statuses.items():\n",
    "                    if tid not in completed and status in ('COMPLETED', 'FAILED', 'CANCELLED'):\n",
    "                        completed.add(tid)\n",
    "                        if pbar:\n",
    "                            pbar.update(1)\n",
    "\n",
    "                if len(completed) == len(self.task_ids):\n",
    "                    return all(s == 'COMPLETED' for s in statuses.values())\n",
    "\n",
    "                time.sleep(poll_interval_sec)\n",
    "\n",
    "            # Timeout reached\n",
    "            return False\n",
    "\n",
    "        finally:\n",
    "            if pbar:\n",
    "                pbar.close()\n",
    "\n",
    "    def cancel(self) -> Dict[str, bool]:\n",
    "        \"\"\"Cancel all running tasks.\n",
    "\n",
    "        Returns:\n",
    "            Dict mapping task_id to success boolean\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for task_id in self.task_ids:\n",
    "            try:\n",
    "                ee.data.cancelTask(task_id)\n",
    "                results[task_id] = True\n",
    "            except Exception:\n",
    "                results[task_id] = False\n",
    "        return results\n",
    "\n",
    "    def failed_tasks(self) -> List[str]:\n",
    "        \"\"\"Get list of failed task IDs.\"\"\"\n",
    "        return [tid for tid, status in self.status().items() if status == 'FAILED']\n",
    "\n",
    "    def completed_tasks(self) -> List[str]:\n",
    "        \"\"\"Get list of completed task IDs.\"\"\"\n",
    "        return [tid for tid, status in self.status().items() if status == 'COMPLETED']\n",
    "\n",
    "    def running_tasks(self) -> List[str]:\n",
    "        \"\"\"Get list of currently running task IDs.\"\"\"\n",
    "        return [tid for tid, status in self.status().items() if status == 'RUNNING']\n",
    "\n",
    "    def results_info(self) -> Dict[str, dict]:\n",
    "        \"\"\"Get info about completed results.\n",
    "\n",
    "        Returns:\n",
    "            Dict mapping task_id to result info including destination URIs\n",
    "        \"\"\"\n",
    "        results = {}\n",
    "        for task_id in self.task_ids:\n",
    "            try:\n",
    "                task_status = ee.data.getTaskStatus(task_id)\n",
    "                if task_status and task_status[0].get('state') == 'COMPLETED':\n",
    "                    results[task_id] = {\n",
    "                        'destination_uris': task_status[0].get('destination_uris', []),\n",
    "                        'chunk': self.chunk_mapping.get(task_id),\n",
    "                        'output_url': task_status[0].get('output_url', [])\n",
    "                    }\n",
    "            except Exception:\n",
    "                pass\n",
    "        return results\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        summary = self.summary()\n",
    "        parts = [f\"{status}={count}\" for status, count in sorted(summary.items())]\n",
    "        return f\"ExportTask(n={len(self.task_ids)}, {', '.join(parts)})\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f2d19c",
   "metadata": {},
   "source": [
    "## Internal Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c4ca32",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _wait_for_task_slot(active_tasks: List[str], max_concurrent: int, poll_sec: int = 5) -> List[str]:\n",
    "    \"\"\"Wait until there's room for another task.\n",
    "\n",
    "    Args:\n",
    "        active_tasks: List of currently active task IDs\n",
    "        max_concurrent: Maximum allowed concurrent tasks\n",
    "        poll_sec: Seconds between checks\n",
    "\n",
    "    Returns:\n",
    "        Updated list of still-active task IDs\n",
    "    \"\"\"\n",
    "    while len(active_tasks) >= max_concurrent:\n",
    "        still_active = []\n",
    "        for task_id in active_tasks:\n",
    "            try:\n",
    "                status = ee.data.getTaskStatus(task_id)\n",
    "                if status and status[0].get('state') in ('READY', 'RUNNING'):\n",
    "                    still_active.append(task_id)\n",
    "            except Exception:\n",
    "                pass  # Assume completed/failed\n",
    "        active_tasks = still_active\n",
    "\n",
    "        if len(active_tasks) >= max_concurrent:\n",
    "            time.sleep(poll_sec)\n",
    "\n",
    "    return active_tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba66f69",
   "metadata": {},
   "source": [
    "## Example Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8611cd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "# Example: Export a large collection to Google Drive\n",
    "from gee_polygons import SiteCollection\n",
    "from gee_polygons.datasets.mapbiomas import MAPBIOMAS_LULC\n",
    "\n",
    "# Load 40,000 sites in lazy mode\n",
    "sites = SiteCollection.from_geojson('all_sites.geojson', lazy=True)\n",
    "\n",
    "# Configure export\n",
    "destination = ExportDestination(\n",
    "    type='drive',\n",
    "    folder='restoration_extractions',\n",
    "    file_prefix='lulc_2024'\n",
    ")\n",
    "\n",
    "config = ExportConfig(\n",
    "    chunk_size=50,      # 50 sites per task\n",
    "    max_concurrent=15   # Run 15 tasks at once\n",
    ")\n",
    "\n",
    "# Submit export (creates ~800 tasks)\n",
    "task = sites.export_categorical(\n",
    "    layer=MAPBIOMAS_LULC,\n",
    "    years=range(2010, 2024),\n",
    "    destination=destination,\n",
    "    config=config\n",
    ")\n",
    "\n",
    "print(f\"Submitted {len(task.task_ids)} export tasks\")\n",
    "\n",
    "# Monitor progress\n",
    "task.wait(timeout_minutes=180)\n",
    "\n",
    "# Check results\n",
    "print(task.summary())\n",
    "print(task.results_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e2eacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
